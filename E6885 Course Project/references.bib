@misc{openai_ppo,
  author = {OpenAI},
  title = {Proximal Policy Optimization Algorithms},
  howpublished = {\url{https://openai.com/blog/openai-baselines-ppo/}},
  year = {2022},
  note = {[Online; accessed 26-June-2022]}
}

@article{wang2018actorcritic,
  title={An Actor-critic Algorithm Using Cross Evaluation of Value Functions},
  author={Wang, Hui and Zhang, Peng and Liu, Quan},
  journal={IAES International Journal of Robotics and Automation (IJRA)},
  volume={7},
  pages={39--47},
  year={2018},
  doi={10.11591/ijra.v7i1.pp39-47}
}

@misc{unity_ml_agents,
  author = {Unity},
  title = {Unity},
  howpublished = {\url{https://unity.com/products/machine-learning-agents}},
  year = {2022},
  note = {[Online; accessed 26-June-2022]}
}

@article{hochreiter1997lstm,
  title={Long Short-term Memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural Computation},
  volume={9},
  pages={1735--1780},
  year={1997},
  doi={10.1162/neco.1997.9.8.1735}
}

@article{mnih2015humanlevel,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, V. and Kavukcuoglu, K. and Silver, D. and others},
  journal={Nature},
  volume={518},
  pages={529--533},
  year={2015},
  doi={10.1038/nature14236}
}

@inproceedings{he2016deepresidual,
  title={Deep Residual Learning for Image Recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={770--778},
  year={2016},
  organization={IEEE},
  doi={10.1109/CVPR.2016.90}
}

@article{kaelbling1996reinforcement,
  title={Reinforcement learning: A survey},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Moore, Andrew W},
  journal={Journal of artificial intelligence research},
  volume={4},
  pages={237--285},
  year={1996}
}

@article{kober2010imitation,
  title={Imitation and reinforcement learning},
  author={Kober, Jens and Peters, Jan},
  journal={IEEE Robotics \& Automation Magazine},
  volume={17},
  number={2},
  pages={55--62},
  year={2010},
  publisher={IEEE}
}

@article{ravichandar2020recent,
  title={Recent advances in robot learning from demonstration},
  author={Ravichandar, Harish and Polydoros, Athanasios S and Chernova, Sonia and Billard, Aude},
  journal={Annual review of control, robotics, and autonomous systems},
  volume={3},
  pages={297--330},
  year={2020},
  publisher={Annual Reviews}
}

@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{tai2017virtual,
  title={Virtual-to-real deep reinforcement learning: Continuous control of mobile robots for mapless navigation},
  author={Tai, Lei and Paolo, Giuseppe and Liu, Ming},
  booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={31--36},
  year={2017},
  organization={IEEE}
}

@inproceedings{cetin2019drone,
  title={Drone navigation and avoidance of obstacles through deep reinforcement learning},
  author={Cetin, Ender and Barrado, Cristina and Mu{\~n}oz, Guillem and Macias, Miquel and Pastor, Enric},
  booktitle={2019 IEEE/AIAA 38th Digital Avionics Systems Conference (DASC)},
  pages={1--7},
  year={2019},
  organization={IEEE}
}

@inproceedings{matignon2012coordinated,
  title={Coordinated multi-robot exploration under communication constraints using decentralized markov decision processes},
  author={Matignon, La{\"e}titia and Jeanpierre, Laurent and Mouaddib, Abdel-Illah},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={26},
  number={1},
  pages={2017--2023},
  year={2012}
}

@article{foerster2016learning,
  title={Learning to communicate with deep multi-agent reinforcement learning},
  author={Foerster, Jakob and Assael, Ioannis Alexandros and De Freitas, Nando and Whiteson, Shimon},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{nair2018overcoming,
  title={Overcoming exploration in reinforcement learning with demonstrations},
  author={Nair, Ashvin and McGrew, Bob and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={6292--6299},
  year={2018},
  organization={IEEE}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@inproceedings{rusu2017sim,
  title={Sim-to-real robot learning from pixels with progressive nets},
  author={Rusu, Andrei A and Ve{\v{c}}er{\'\i}k, Matej and Roth{\"o}rl, Thomas and Heess, Nicolas and Pascanu, Razvan and Hadsell, Raia},
  booktitle={Conference on robot learning},
  pages={262--270},
  year={2017},
  organization={PMLR}
}

@inproceedings{james2019sim,
  title={Sim-to-real via sim-to-sim: Data-efficient robotic grasping via randomized-to-canonical adaptation networks},
  author={James, Stephen and Wohlhart, Paul and Kalakrishnan, Mrinal and Kalashnikov, Dmitry and Irpan, Alex and Ibarz, Julian and Levine, Sergey and Hadsell, Raia and Bousmalis, Konstantinos},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12627--12637},
  year={2019}
}

@article{juliani2020,
  title={Unity: A general platform for intelligent agents},
  author={Juliani, Arthur and Berges, Vincent-Pierre and Teng, Ervin and Cohen, Andrew and Harper, Jonathan and Elion, Chris and Goy, Chris and Gao, Yuan and Henry, Hunter and Mattar, Marwan and Lange, Danny},
  journal={arXiv preprint arXiv:1809.02627},
  url={https://arxiv.org/pdf/1809.02627.pdf},
  year={2020}
}